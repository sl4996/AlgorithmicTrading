{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "287b4850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "import os\n",
    "import random\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data as data_u\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a347086",
   "metadata": {},
   "source": [
    "### Creating the Training Data (creating the labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the stock names\n",
    "stocks = pd.read_excel('Data/universe.xlsx')['symbol'][:50]\n",
    "\n",
    "# convert pd Series of strings into one long string (that the format yf wants)\n",
    "string_format_stocks = stocks.str.cat(sep=' ')\n",
    "\n",
    "# fetch the data\n",
    "prices = yf.download(string_format_stocks, start='2010-01-01', end=dt.today().strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c55b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.reset_index(inplace=True)\n",
    "prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de878220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the dates to use in the sliding window\n",
    "dates = prices['Date']\n",
    "\n",
    "# create windows of 15 days that jump every 5 days (5 days overlap)\n",
    "windows = sliding_window_view(dates, window_shape = 15)[::5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e623c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to assign reccomendation given return\n",
    "def assign_recommendation(ret):\n",
    "    if ret < -0.1:\n",
    "        recommendation = 'strong sell'\n",
    "    elif ret < -0.02:\n",
    "        recommendation = 'sell'\n",
    "    elif ret < 0.05:\n",
    "        recommendation = 'neutral'\n",
    "    elif ret < 0.1:\n",
    "        recommendation = 'buy'\n",
    "    else:\n",
    "        recommendation = 'strong buy'\n",
    "    return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45310458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array to store the associated following week returns for each window\n",
    "counter = 0\n",
    "\n",
    "# specify the test ratio\n",
    "test_ratio = 0.2\n",
    "\n",
    "# loop through each stock and then through the windows\n",
    "for stock in stocks:\n",
    "    # extract the current stock data\n",
    "    current_stock = prices.iloc[:, (prices.columns.get_level_values(1)==stock) | (prices.columns.get_level_values(0)=='Date')]\n",
    "\n",
    "    # drop the multiindex column names (stock name is uneccessary)\n",
    "    current_stock = current_stock.droplevel(level=1, axis=1)\n",
    "    \n",
    "    # some stocks dont have historical data from year 2010, so drop na\n",
    "    current_stock.dropna(inplace=True)\n",
    "        \n",
    "    for i in range(len(windows)-1):\n",
    "\n",
    "        # slice the dataframe\n",
    "        window_data = current_stock.loc[prices['Date'].isin(windows[i])]\n",
    "        \n",
    "        if len(window_data) == 15:\n",
    "            \n",
    "            # allocate test_ratio of images to the test folder, others to the train folder\n",
    "            test = random.random() < test_ratio\n",
    "            train_or_test = 'test' if test else 'train'\n",
    "\n",
    "            # make the figure\n",
    "            fig = go.Figure(data=[go.Candlestick(x=window_data['Date'], open=window_data['Open'], high=window_data['High'],\n",
    "                                                 low=window_data['Low'], close=window_data['Close'])])\n",
    "\n",
    "            # remove uneccessary stuff from the figure\n",
    "            fig.update_yaxes(showticklabels=False)\n",
    "            fig.update_xaxes(showticklabels=False)\n",
    "            fig.update_layout(xaxis_rangeslider_visible=False)\n",
    "            \n",
    "            # find the associated next week return\n",
    "            next_window_data = current_stock.loc[current_stock['Date'].isin(windows[i+1])]\n",
    "            next_window_data.reset_index(inplace=True, drop=True) # to have the index always from 0 to 9\n",
    "            following_week_return = next_window_data['Adj Close'].pct_change(periods=5)[5].round(3)\n",
    "            recommendation = assign_recommendation(following_week_return)\n",
    "            \n",
    "            \n",
    "            path = f'pattern_images/{train_or_test}/{recommendation}/'\n",
    "\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "                \n",
    "            # save the figure\n",
    "            fig.write_image(path + f'fig {counter}.png')\n",
    "\n",
    "\n",
    "            # increase the counter\n",
    "            counter += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8ef05f",
   "metadata": {},
   "source": [
    "### Train CNN on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e30311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_images = len(glob.glob('pattern_images/*'))\n",
    "\n",
    "# data = []\n",
    "# for i in range(num_images):\n",
    "#     image = cv2.imread(f'pattern_images/fig {i}.png')\n",
    "#     image = cv2.resize(image, (150, 150))\n",
    "#     associated_return = associated_returns[i]\n",
    "#     data.append([image, associated_return])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6debf038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms\n",
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((150,150)),  # resize the image\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5],\n",
    "                         [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48b56061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "\n",
    "train_path = 'pattern_images/train'\n",
    "test_path = 'pattern_images/test'\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path, transform=transformer),\n",
    "    batch_size = 64, shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path, transform=transformer),\n",
    "    batch_size = 64, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e9d660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'buy', 'neutral', 'sell', 'strong buy', 'strong sell']\n"
     ]
    }
   ],
   "source": [
    "# Categories\n",
    "path = Path(train_path)\n",
    "categories = sorted([category.name.split('/')[-1] for category in path.iterdir()])\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b38f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # output size after convolution filter: ((w-f+2p)/s)+1\n",
    "        \n",
    "        # input shape = (64, 3, 150, 150)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # input shape = (64, 12, 150, 150)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=12)\n",
    "        \n",
    "        # input shape = (64, 12, 150, 150)\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=20, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # input shape = (64, 20, 150, 150)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=20)\n",
    "        \n",
    "        # input shape = (64, 20, 150, 150)\n",
    "        self.conv3 = nn.Conv2d(in_channels=20, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # input shape = (64, 32, 150, 150)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # input shape = (64, 32, 75, 75)\n",
    "        self.fc1 = nn.Linear(in_features=32 * 75 * 75, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.fc3 = nn.Linear(in_features=60, out_features=num_classes)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Network(num_classes=len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8496e023",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4a77497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training images: 23211\n",
      "number of testing images: 5989\n"
     ]
    }
   ],
   "source": [
    "train_count = len(glob.glob(train_path+'/*/*.png'))\n",
    "test_count = len(glob.glob(test_path+'/*/*.png'))\n",
    "print('number of training images:', train_count)\n",
    "print('number of testing images:', test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bbe788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    \"\"\"\n",
    "        Initialize weights of the model to random normal\n",
    "    \"\"\"\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "def evaluate_accuracy(data_iter, net, device=torch.device('cpu')):\n",
    "    \"\"\"\n",
    "        Evaluate accuracy of a model on the given data set\n",
    "    \"\"\"\n",
    "    net.eval()  # Switch to evaluation mode for Dropout, BatchNorm etc layers.\n",
    "    acc_sum, n = torch.tensor([0], dtype=torch.float32, device=device), 0\n",
    "    for X, y in data_iter:\n",
    "        # Copy the data to device.\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            y = y.long()\n",
    "            acc_sum += torch.sum((torch.argmax(net(X), dim=1) == y))\n",
    "            n += y.shape[0]\n",
    "    return acc_sum.item()/n\n",
    "\n",
    "def train(num_epochs=5, previous_epochs=0):\n",
    "    \"\"\"\n",
    "        Train the model\n",
    "    \"\"\"\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)          # get model predictions\n",
    "            loss = loss_fn(outputs, labels)  # calculate the loss\n",
    "            loss.backward()                  # backward propagation\n",
    "            optimizer.step()                 # update weights and biases\n",
    "\n",
    "            labels = labels.type(torch.float32)\n",
    "            train_l_sum += loss.item()\n",
    "            train_acc_sum += torch.sum((torch.argmax(outputs, dim=1).type(torch.FloatTensor) == labels).detach()).float()\n",
    "            n += list(labels.size())[0]\n",
    "\n",
    "        # print statistics\n",
    "        test_acc = evaluate_accuracy(test_loader, model)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f' % (epoch + previous_epochs + 1, train_l_sum / n, train_acc_sum / n, test_acc))\n",
    "\n",
    "    print('Finished Training')\n",
    "    \n",
    "def overall_test_accuracy():\n",
    "    \"\"\"\n",
    "        Calculate the overall test accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the test images: {100 * correct // total} %')\n",
    "    \n",
    "def per_class_category():\n",
    "    \"\"\"\n",
    "        Calculate the accuracy per class\n",
    "    \"\"\"\n",
    "\n",
    "    # prepare to count predictions for each class\n",
    "    correct_pred = {classname: 0 for classname in categories}\n",
    "    total_pred = {classname: 0 for classname in categories}\n",
    "\n",
    "    # again no gradients needed\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            # collect the correct predictions for each class\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                if label == prediction:\n",
    "                    correct_pred[categories[label]] += 1\n",
    "                total_pred[categories[label]] += 1\n",
    "\n",
    "\n",
    "    # print accuracy for each class\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        try:\n",
    "            accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        except ZeroDivisionError:\n",
    "            accuracy = 0\n",
    "\n",
    "        print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb811ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(12, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=180000, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (fc3): Linear(in_features=60, out_features=6, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize weights to random numbers\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5e65a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.0080, train acc 0.798, test acc 0.814\n",
      "epoch 2, loss 0.0065, train acc 0.831, test acc 0.817\n",
      "epoch 3, loss 0.0055, train acc 0.854, test acc 0.831\n",
      "epoch 4, loss 0.0043, train acc 0.888, test acc 0.827\n",
      "epoch 5, loss 0.0028, train acc 0.927, test acc 0.812\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "num_epochs = 5\n",
    "train(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eca203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2bcac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 81 %\n",
      "Accuracy for class: .DS_Store is 38.4 %\n",
      "Accuracy for class: buy   is 91.4 %\n",
      "Accuracy for class: neutral is 67.6 %\n",
      "Accuracy for class: sell  is 12.5 %\n",
      "Accuracy for class: strong buy is 35.5 %\n",
      "Accuracy for class: strong sell is 0.0 %\n"
     ]
    }
   ],
   "source": [
    "# check the accuract of the model\n",
    "overall_test_accuracy()\n",
    "per_class_category()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b8f281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
