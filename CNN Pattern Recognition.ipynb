{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "287b4850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "import os\n",
    "import random\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data as data_u\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a347086",
   "metadata": {},
   "source": [
    "### Creating the Training Data (creating the labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1bce75d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    }
   ],
   "source": [
    "# read the stock names\n",
    "stocks = pd.read_excel('Data/universe.xlsx')['symbol'][:50]\n",
    "\n",
    "# convert pd Series of strings into one long string (that the format yf wants)\n",
    "string_format_stocks = stocks.str.cat(sep=' ')\n",
    "\n",
    "# fetch the data\n",
    "prices = yf.download(string_format_stocks, start='2010-01-01', end=dt.today().strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9c55b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nz/jhg_xmnj7kn3vcf8309msskc0000gp/T/ipykernel_80646/3633743968.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  prices.reset_index(inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th colspan=\"9\" halign=\"left\">Adj Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ACN</th>\n",
       "      <th>AEP</th>\n",
       "      <th>AIZ</th>\n",
       "      <th>ALLE</th>\n",
       "      <th>AMAT</th>\n",
       "      <th>AMP</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>AVB</th>\n",
       "      <th>...</th>\n",
       "      <th>PYPL</th>\n",
       "      <th>RE</th>\n",
       "      <th>ROL</th>\n",
       "      <th>ROST</th>\n",
       "      <th>UNH</th>\n",
       "      <th>URI</th>\n",
       "      <th>V</th>\n",
       "      <th>VRSK</th>\n",
       "      <th>WRK</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.970905</td>\n",
       "      <td>21.340599</td>\n",
       "      <td>23.350733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.356113</td>\n",
       "      <td>29.852716</td>\n",
       "      <td>6.6950</td>\n",
       "      <td>54.045589</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>444800</td>\n",
       "      <td>839363</td>\n",
       "      <td>15743600</td>\n",
       "      <td>12199500</td>\n",
       "      <td>1692500</td>\n",
       "      <td>20180000</td>\n",
       "      <td>390000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27809100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.174686</td>\n",
       "      <td>21.096291</td>\n",
       "      <td>24.047535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.268759</td>\n",
       "      <td>30.548885</td>\n",
       "      <td>6.7345</td>\n",
       "      <td>53.639587</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>327200</td>\n",
       "      <td>701663</td>\n",
       "      <td>9369600</td>\n",
       "      <td>11180700</td>\n",
       "      <td>1459200</td>\n",
       "      <td>25833600</td>\n",
       "      <td>430000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30174700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.527359</td>\n",
       "      <td>21.310055</td>\n",
       "      <td>23.977858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.244936</td>\n",
       "      <td>30.975569</td>\n",
       "      <td>6.6125</td>\n",
       "      <td>53.133747</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>266400</td>\n",
       "      <td>841388</td>\n",
       "      <td>13144800</td>\n",
       "      <td>9761100</td>\n",
       "      <td>1072900</td>\n",
       "      <td>16254000</td>\n",
       "      <td>848900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35044700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.496002</td>\n",
       "      <td>21.493298</td>\n",
       "      <td>24.272064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.125816</td>\n",
       "      <td>31.207605</td>\n",
       "      <td>6.5000</td>\n",
       "      <td>53.240250</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>354600</td>\n",
       "      <td>536119</td>\n",
       "      <td>23984800</td>\n",
       "      <td>11789800</td>\n",
       "      <td>2052800</td>\n",
       "      <td>27841200</td>\n",
       "      <td>426600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27192100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.362778</td>\n",
       "      <td>21.749826</td>\n",
       "      <td>24.287550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.554646</td>\n",
       "      <td>31.319889</td>\n",
       "      <td>6.6760</td>\n",
       "      <td>52.840878</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>276900</td>\n",
       "      <td>330581</td>\n",
       "      <td>15926000</td>\n",
       "      <td>7228700</td>\n",
       "      <td>1399000</td>\n",
       "      <td>11907200</td>\n",
       "      <td>253200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24891800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Adj Close                                                   \\\n",
       "                  ABBV        ACN        AEP        AIZ ALLE       AMAT   \n",
       "0 2010-01-04       NaN  32.970905  21.340599  23.350733  NaN  11.356113   \n",
       "1 2010-01-05       NaN  33.174686  21.096291  24.047535  NaN  11.268759   \n",
       "2 2010-01-06       NaN  33.527359  21.310055  23.977858  NaN  11.244936   \n",
       "3 2010-01-07       NaN  33.496002  21.493298  24.272064  NaN  11.125816   \n",
       "4 2010-01-08       NaN  33.362778  21.749826  24.287550  NaN  11.554646   \n",
       "\n",
       "                                 ... Volume                            \\\n",
       "         AMP    AMZN        AVB  ...   PYPL      RE     ROL      ROST   \n",
       "0  29.852716  6.6950  54.045589  ...    NaN  444800  839363  15743600   \n",
       "1  30.548885  6.7345  53.639587  ...    NaN  327200  701663   9369600   \n",
       "2  30.975569  6.6125  53.133747  ...    NaN  266400  841388  13144800   \n",
       "3  31.207605  6.5000  53.240250  ...    NaN  354600  536119  23984800   \n",
       "4  31.319889  6.6760  52.840878  ...    NaN  276900  330581  15926000   \n",
       "\n",
       "                                                      \n",
       "        UNH      URI         V    VRSK WRK       XOM  \n",
       "0  12199500  1692500  20180000  390000 NaN  27809100  \n",
       "1  11180700  1459200  25833600  430000 NaN  30174700  \n",
       "2   9761100  1072900  16254000  848900 NaN  35044700  \n",
       "3  11789800  2052800  27841200  426600 NaN  27192100  \n",
       "4   7228700  1399000  11907200  253200 NaN  24891800  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices.reset_index(inplace=True)\n",
    "prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de878220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the dates to use in the sliding window\n",
    "dates = prices['Date']\n",
    "\n",
    "# create windows of 15 days that jump every 5 days (5 days overlap)\n",
    "windows = sliding_window_view(dates, window_shape = 15)[::5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e623c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to assign reccomendation given return\n",
    "def assign_recommendation(ret):\n",
    "    if ret < -0.1:\n",
    "        recommendation = 'strong sell'\n",
    "    elif ret < -0.02:\n",
    "        recommendation = 'sell'\n",
    "    elif ret < 0.05:\n",
    "        recommendation = 'neutral'\n",
    "    elif ret < 0.1:\n",
    "        recommendation = 'buy'\n",
    "    else:\n",
    "        recommendation = 'strong buy'\n",
    "    return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45310458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array to store the associated following week returns for each window\n",
    "counter = 0\n",
    "\n",
    "# specify the test ratio\n",
    "test_ratio = 0.2\n",
    "\n",
    "# loop through each stock and then through the windows\n",
    "for stock in stocks:\n",
    "    # extract the current stock data\n",
    "    current_stock = prices.iloc[:, (prices.columns.get_level_values(1)==stock) | (prices.columns.get_level_values(0)=='Date')]\n",
    "\n",
    "    # drop the multiindex column names (stock name is uneccessary)\n",
    "    current_stock = current_stock.droplevel(level=1, axis=1)\n",
    "    \n",
    "    # some stocks dont have historical data from year 2010, so drop na\n",
    "    current_stock.dropna(inplace=True)\n",
    "        \n",
    "    for i in range(len(windows)-1):\n",
    "\n",
    "        # slice the dataframe\n",
    "        window_data = current_stock.loc[prices['Date'].isin(windows[i])]\n",
    "        \n",
    "        if len(window_data) == 15:\n",
    "            \n",
    "            # allocate test_ratio of images to the test folder, others to the train folder\n",
    "            test = random.random() < test_ratio\n",
    "            train_or_test = 'test' if test else 'train'\n",
    "\n",
    "            # make the figure\n",
    "            fig = go.Figure(data=[go.Candlestick(x=window_data['Date'], open=window_data['Open'], high=window_data['High'],\n",
    "                                                 low=window_data['Low'], close=window_data['Close'])])\n",
    "\n",
    "            # remove uneccessary stuff from the figure\n",
    "            fig.update_yaxes(showticklabels=False)\n",
    "            fig.update_xaxes(showticklabels=False)\n",
    "            fig.update_layout(xaxis_rangeslider_visible=False)\n",
    "            \n",
    "            # find the associated next week return\n",
    "            next_window_data = current_stock.loc[current_stock['Date'].isin(windows[i+1])]\n",
    "            next_window_data.reset_index(inplace=True, drop=True) # to have the index always from 0 to 9\n",
    "            following_week_return = next_window_data['Adj Close'].pct_change(periods=5)[5].round(3)\n",
    "            recommendation = assign_recommendation(following_week_return)\n",
    "            \n",
    "            \n",
    "            path = f'pattern_images/{train_or_test}/{recommendation}/'\n",
    "\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "                \n",
    "            # save the figure\n",
    "            fig.write_image(path + f'fig {counter}.png')\n",
    "\n",
    "\n",
    "            # increase the counter\n",
    "            counter += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8ef05f",
   "metadata": {},
   "source": [
    "### Train CNN on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3e30311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_images = len(glob.glob('pattern_images/*'))\n",
    "\n",
    "# data = []\n",
    "# for i in range(num_images):\n",
    "#     image = cv2.imread(f'pattern_images/fig {i}.png')\n",
    "#     image = cv2.resize(image, (150, 150))\n",
    "#     associated_return = associated_returns[i]\n",
    "#     data.append([image, associated_return])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6debf038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms\n",
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((150,150)),  # resize the image\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5],\n",
    "                         [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48b56061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "\n",
    "train_path = 'pattern_images/train'\n",
    "test_path = 'pattern_images/test'\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path, transform=transformer),\n",
    "    batch_size = 250, shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path, transform=transformer),\n",
    "    batch_size = 250, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e9d660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buy', 'neutral', 'sell', 'strong buy', 'strong sell']\n"
     ]
    }
   ],
   "source": [
    "# Categories\n",
    "path = Path(train_path)\n",
    "categories = sorted([category.name.split('/')[-1] for category in path.iterdir()])\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b38f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # output size after convolution filter: ((w-f+2p)/s)+1\n",
    "        \n",
    "        # input shape = (10, 3, 150, 150)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # input shape = (10, 12, 150, 150)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=12)\n",
    "        \n",
    "        # input shape = (10, 12, 150, 150)\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=20, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # input shape = (10, 12, 150, 150)\n",
    "        self.conv3 = nn.Conv2d(in_channels=20, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # input shape = (10, 12, 150, 150)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # input shape = (10, 32, 75, 75)\n",
    "        self.fc1 = nn.Linear(in_features=32 * 75 * 75, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.fc3 = nn.Linear(in_features=60, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Network(num_classes=len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8496e023",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e4a77497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training images: 23211\n",
      "number of testing images: 5989\n"
     ]
    }
   ],
   "source": [
    "train_count = len(glob.glob(train_path+'/*/*.png'))\n",
    "test_count = len(glob.glob(test_path+'/*/*.png'))\n",
    "print('number of training images:', train_count)\n",
    "print('number of testing images:', test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5bbe788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    \"\"\"\n",
    "        Initialize weights of the model to random normal\n",
    "    \"\"\"\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "def evaluate_accuracy(data_iter, net, device=torch.device('cpu')):\n",
    "    \"\"\"\n",
    "        Evaluate accuracy of a model on the given data set\n",
    "    \"\"\"\n",
    "    net.eval()  # Switch to evaluation mode for Dropout, BatchNorm etc layers.\n",
    "    acc_sum, n = torch.tensor([0], dtype=torch.float32, device=device), 0\n",
    "    for X, y in data_iter:\n",
    "        # Copy the data to device.\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            y = y.long()\n",
    "            acc_sum += torch.sum((torch.argmax(net(X), dim=1) == y))\n",
    "            n += y.shape[0]\n",
    "    return acc_sum.item()/n\n",
    "\n",
    "def train(num_epochs=5, previous_epochs=0):\n",
    "    \"\"\"\n",
    "        Train the model\n",
    "    \"\"\"\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)          # get model predictions\n",
    "            loss = loss_fn(outputs, labels)  # calculate the loss\n",
    "            loss.backward()                  # backward propagation\n",
    "            optimizer.step()                 # update weights and biases\n",
    "\n",
    "            labels = labels.type(torch.float32)\n",
    "            train_l_sum += loss.item()\n",
    "            train_acc_sum += torch.sum((torch.argmax(outputs, dim=1).type(torch.FloatTensor) == labels).detach()).float()\n",
    "            n += list(labels.size())[0]\n",
    "\n",
    "        # print statistics\n",
    "        test_acc = evaluate_accuracy(test_loader, model)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f' % (epoch + previous_epochs + 1, train_l_sum / n, train_acc_sum / n, test_acc))\n",
    "\n",
    "    print('Finished Training')\n",
    "    \n",
    "def overall_test_accuracy():\n",
    "    \"\"\"\n",
    "        Calculate the overall test accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the test images: {100 * correct // total} %')\n",
    "    \n",
    "def per_class_category():\n",
    "    \"\"\"\n",
    "        Calculate the accuracy per class\n",
    "    \"\"\"\n",
    "\n",
    "    # prepare to count predictions for each class\n",
    "    correct_pred = {classname: 0 for classname in categories}\n",
    "    total_pred = {classname: 0 for classname in categories}\n",
    "\n",
    "    # again no gradients needed\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            # collect the correct predictions for each class\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                if label == prediction:\n",
    "                    correct_pred[categories[label]] += 1\n",
    "                total_pred[categories[label]] += 1\n",
    "\n",
    "\n",
    "    # print accuracy for each class\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        try:\n",
    "            accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        except ZeroDivisionError:\n",
    "            accuracy = 0\n",
    "\n",
    "        print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cb811ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(12, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=180000, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (fc3): Linear(in_features=60, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize weights to random numbers\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e65a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.0024, train acc 0.773, test acc 0.814\n",
      "epoch 2, loss 0.0016, train acc 0.836, test acc 0.821\n",
      "epoch 3, loss 0.0013, train acc 0.861, test acc 0.819\n",
      "epoch 4, loss 0.0011, train acc 0.894, test acc 0.821\n",
      "epoch 5, loss 0.0008, train acc 0.926, test acc 0.817\n",
      "epoch 6, loss 0.0005, train acc 0.957, test acc 0.817\n",
      "epoch 7, loss 0.0003, train acc 0.976, test acc 0.802\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "num_epochs = 8\n",
    "train(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5eca203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c2bcac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 6 %\n",
      "Accuracy for class: buy   is 100.0 %\n",
      "Accuracy for class: neutral is 0.0 %\n",
      "Accuracy for class: sell  is 0.0 %\n",
      "Accuracy for class: strong buy is 0.0 %\n",
      "Accuracy for class: strong sell is 0.0 %\n"
     ]
    }
   ],
   "source": [
    "# check the accuract of the model\n",
    "overall_test_accuracy()\n",
    "per_class_category()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b8f281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
